---
keyword: [报警配置, 报警规则模板, 报警, 监控]
---

# 容器服务报警管理

报警配置功能提供容器场景报警能力的统一管理，包括容器服务异常事件报警，以及容器场景指标报警，支持在创建集群时默认开启报警功能。容器服务的报警规则支持通过集群内部署CRD的方式配置管理。本文介绍如何接入报警配置功能及授予报警功能资源的访问权限。

## 功能使用场景

容器服务报警配置功能集合容器场景的监控报警能力，提供报警的统一配置管理，有如下几个典型的使用场景：

-   **集群运维**

    可以通过监控报警第一时间了解集群管控、存储、网络、弹性扩缩容等异常事件。例如，可通过配置并查看**集群异常事件报警规则集**感知集群节点或容器节点通用异常；通过配置并查看**集群存储异常事件报警规则集**感知集群存储的变更与异常；通过配置并查看**集群网络异常事件报警规则集**感知集群网络的变更与异常；通过配置并查看**集群管控运维异常报警规则集**感知集群管控的变更与异常等。

-   **应用开发**

    可以通过监控报警第一时间了解在集群中运行应用的异常事件、指标是否异常。例如，集群容器副本异常或者应用Deployment的CPU、内存水位指标是否超过阈值等。可通过开启报警配置功能中的默认报警规则模板，即可快速接受集群内应用容器副本的异常事件报警通知。例如，通过配置并订阅关注**集群容器副本异常报警规则集**感知所属应用的Pod是否异常。

-   **应用管理**

    关注运行在集群上的应用健康、容量规划、集群运行稳定性及异常甚至是错误报警等贯穿应用生命周期的一系列问题。例如，通过配置并订阅关注**集群重要事件报警规则集**感知集群内所有Warning、Error等异常报警；关注**集群资源异常报警规则集**感知集群的资源情况，从而更好地做容量规划等。

-   **多集群管理**

    当您有多个集群需要管理，为集群配置报警规则往往会是一个重复繁琐且难以同步的操作。容器服务报警配置功能，支持通过集群内部署**CRD配置的方式管理报警规则**。可通过维护多个集群中同样配置的CRD资源，来方便快捷地实现多集群中报警规则的同步配置。


## 组件安装与升级

控制台会自动检测报警配置环境是否符合要求，并会引导进行开通或安装、升级组件。

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，单击**集群**。

3.  在集群列表页面中，单击目标集群名称或者目标集群右侧**操作**列下的**详情**。

4.  在集群管理页左侧导航栏，选择**运维管理** \> **报警配置**。

5.  在报警配置页面控制台会自动检查以下条件。

    若不符合条件，请按以下提示完成操作。

    -   已开通SLS日志服务云产品。当您首次使用日志服务时，需要登录[日志服务控制台](https://sls.console.aliyun.com)，根据页面提示开通日志服务。
    -   已安装**事件中心**。具体操作，请参见[事件监控](/cn.zh-CN/Kubernetes集群用户指南/可观测性/监控管理/事件监控.md)。
    -   集群托管组件alicloud-monitor-controller升级到最新版本。更多信息，请参见[alicloud-monitor-controller](/cn.zh-CN/产品发布记录/组件介绍与变更记录/日志与监控/alicloud-monitor-controller.md)。
    ![报警配置](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/6282476161/p255151.png)


## 如何接入报警配置功能

目前容器服务报警规则配置功能支持ACK托管版集群、ACK专有版集群。

**步骤一：开启默认报警规则**

-   创建ACK托管版集群时，打开**使用默认报警模板配置报警**开关，并选择报警通知联系人分组。

    开启后将会创建默认报警规则，并默认发送报警通知到此联系人分组。

    ![创建集群](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/1842085161/p246618.png)

    具体操作，请参见[创建Kubernetes托管版集群](/cn.zh-CN/Kubernetes集群用户指南/集群/创建集群/创建Kubernetes托管版集群.md)。

-   若已创建集群，可在目标集群开启对应报警规则。

    1.  在目标集群左侧导航栏选择**运维管理** \> **报警配置**配置管理。
    2.  在报警规则管理页签，打开**启动状态**可开启对应报警规则集。
    ![报警规则管理](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/9305476161/p249722.png)

    具体操作，请参见[步骤二：手动配置报警规则](#step_pjq_wu5_deg)。


**步骤二：手动配置报警规则**

ACK托管版集群、ACK专有版集群创建后，可进行报警规则、联系人和联系人分组管理。

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，单击**集群**。

3.  在集群列表页面中，单击目标集群名称或者目标集群右侧**操作**列下的**详情**。

4.  在集群管理页左侧导航栏，选择**运维管理** \> **报警配置**。

    |功能特性|说明|
    |----|--|
    |**报警规则管理**|    -   容器服务报警规则功能会默认生成容器场景下的报警模板（包含异常事件报警、异常指标报警）。
    -   报警规则被分类为若干个报警规则集，可为报警规则集关联多个联系人分组，并启动或关闭报警规则集。
    -   报警规则集中包含多个报警规则，一个报警规则对应单个异常的检查项。多个报警规则集可以通过一个YAML资源配置到对应集群中，修改YAML会同步生成报警规则。
    -   关于报警规则YAML配置，请参见[如何通过CRD配置报警规则](#section_9ua_z95_ugc)。
    -   关于默认报警规则模板，请参见[默认报警规则模板](#section_mrd_x9o_nrr)。 |
    |**报警历史**|目前可查看最近发送的近100条历史记录。单击对应报警**报警规则类型**的链接，可跳转到对应监控系统中查看详细规则配置；单击对应报警**排查现场**的链接可快速定位到异常发生的资源页面（异常事件、指标异常的资源）。![报警历史查看](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/5628476161/p255435.png) |
    |**联系人管理**|对联系人进行管理，可创建、编辑或删除联系人。|
    |**联系人分组管理**|对联系人分组进行管理，可创建、编辑或删除联系人分组。当无联系人分组时，控制台会从您的阿里云账号注册信息中同步创建一个默认联系人分组。|

5.  在报警规则管理页签，单击**编辑联系人分组**可设置关联的联系人分组；打开**启动状态**可开启对应报警规则集。


## 如何通过CRD配置报警规则

报警配置功能开启时，会默认在kube-system Namespace下创建一个AckAlertRule类型的资源配置，包含默认报警规则模板。容器服务报警规则集可通过此资源配置在集群中。

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，单击**集群**。

3.  在集群列表页面中，单击目标集群名称或者目标集群右侧**操作**列下的**详情**。

4.  在集群管理页左侧导航栏，选择**运维管理** \> **报警配置**。

5.  在报警规则管理页签中，单击右上角**编辑报警配置**，可查看当前集群中的AckAlertRule资源配置，并可通过YAML文件修改。

    报警规则配置的YAML文件示例如下：

    ```
    apiVersion: alert.alibabacloud.com/v1beta1
    kind: AckAlertRule
    metadata:
      name: default
    spec:
      groups:
        - name: pod-exceptions                     ## 报警规则集名。
          rules:
            - name: pod-oom                        ## 报警规则名。
              type: event                          ## 报警规则类型，枚举值为event（事件类型）、metric（指标类型）。
              expression: sls.app.ack.pod.oom      ## 报警规则表达式，当规则类型为event时，表达式的值为SLS日志服务事件报警sls_event_id。
              enable: enable                       ## 报警规则开启状态，枚举值为enable、disable。
            - name: pod-failed
              type: event
              expression: sls.app.ack.pod.failed
              enable: enable
    ```


## 默认报警规则模板

在以下情况下ACK会默认创建相应报警规则：

-   开启默认报警规则功能。
-   未开启默认报警规则，首次进入报警规则页面。

默认创建的报警规则如下表所示。

|规则集类型|规则名|ACK\_CR\_Rule\_Name|SLS\_Event\_ID|
|-----|---|-------------------|--------------|
|critical-events集群重要事件报警规则集|集群error事件|error-event|sls.app.ack.error|
|集群warning事件|warn-event|sls.app.ack.warn|
|cluster-error集群异常事件报警规则集|集群节点docker进程异常|docker-hang|sls.app.ack.docker.hang|
|集群驱逐事件|eviction-event|sls.app.ack.eviction|
|集群GPU的XID错误事件|gpu-xid-error|sls.app.ack.gpu.xid\_error|
|集群节点重启|node-restart|sls.app.ack.node.restart|
|集群节点时间服务异常|node-ntp-down|sls.app.ack.ntp.down|
|集群节点PLEG异常|node-pleg-error|sls.app.ack.node.pleg\_error|
|集群节点进程异常|ps-hang|sls.app.ack.ps.hang|
|res-exceptions集群资源异常报警规则集|集群节点文件句柄过多|node-fd-pressure|sls.app.ack.node.fd\_pressure|
|集群节点磁盘空间不足|node-disk-pressure|sls.app.ack.node.disk\_pressure|
|集群节点进程数过多|node-pid-pressure|sls.app.ack.node.pid\_pressure|
|集群节点调度资源不足|node-res-insufficient|sls.app.ack.resource.insufficient|
|集群节点IP资源不足|node-ip-pressure|sls.app.ack.ip.not\_enough|
|pod-exceptions集群容器副本异常报警规则集|集群容器副本OOM|pod-oom|sls.app.ack.pod.oom|
|集群容器副本启动失败|pod-failed|sls.app.ack.pod.failed|
|集群镜像拉取失败事件|image-pull-back-off|sls.app.ack.image.pull\_back\_off|
|cluster-ops-err集群管控运维异常报警规则集|无可用LoadBalancer|slb-no-ava|sls.app.ack.ccm.no\_ava\_slb|
|同步LoadBalancer失败|slb-sync-err|sls.app.ack.ccm.sync\_slb\_failed|
|删除LoadBalancer失败|slb-del-err|sls.app.ack.ccm.del\_slb\_failed|
|删除节点失败|node-del-err|sls.app.ack.ccm.del\_node\_failed|
|添加节点失败|node-add-err|sls.app.ack.ccm.add\_node\_failed|
|创建VPC网络路由失败|route-create-err|sls.app.ack.ccm.create\_route\_failed|
|同步VPC网络路由失败|route-sync-err|sls.app.ack.ccm.sync\_route\_failed|
|安全巡检发现高危风险配置|si-c-a-risk|sls.app.ack.si.config\_audit\_high\_risk|
|托管节点池命令执行失败|nlc-run-cmd-err|sls.app.ack.nlc.run\_command\_fail|
|托管节点池未提供任务的具体命令|nlc-empty-cmd|sls.app.ack.nlc.empty\_task\_cmd|
|托管节点池出现未实现的任务模式|nlc-url-m-unimp|sls.app.ack.nlc.url\_mode\_unimpl|
|托管节点池发生未知的修复操作|nlc-opt-no-found|sls.app.ack.nlc.op\_not\_found|
|托管节点池销毁节点发生错误|nlc-des-node-err|sls.app.ack.nlc.destroy\_node\_fail|
|托管节点池节点排水失败|nlc-drain-node-err|sls.app.ack.nlc.drain\_node\_fail|
|托管节点池重启ECS未达到终态|nlc-restart-ecs-wait|sls.app.ack.nlc.restart\_ecs\_wait\_fail|
|托管节点池重启ECS失败|nlc-restart-ecs-err|sls.app.ack.nlc.restart\_ecs\_fail|
|托管节点池重置ECS失败|nlc-reset-ecs-err|sls.app.ack.nlc.reset\_ecs\_fail|
|托管节点池自愈任务失败|nlc-sel-repair-err|sls.app.ack.nlc.repair\_fail|
|cluster-network-err集群网络异常事件报警规则集|Terway资源无效|terway-invalid-res|sls.app.ack.terway.invalid\_resource|
|Terway分配IP失败|terway-alloc-ip-err|sls.app.ack.terway.alloc\_ip\_fail|
|解析ingress带宽配置失败|terway-parse-err|sls.app.ack.terway.parse\_fail|
|Terway分配网络资源失败|terway-alloc-res-err|sls.app.ack.terway.allocate\_failure|
|Terway回收网络资源失败|terway-dispose-err|sls.app.ack.terway.dispose\_failure|
|Terway虚拟模式变更|terway-virt-mod-err|sls.app.ack.terway.virtual\_mode\_change|
|Terway触发PodIP配置检查|terway-ip-check|sls.app.ack.terway.config\_check|
|Ingress重载配置失败|ingress-reload-err|sls.app.ack.ingress.err\_reload\_nginx|
|cluster-storage-err集群存储异常事件报警规则集|云盘容量少于20Gi限制|csi\_invalid\_size|sls.app.ack.csi.invalid\_disk\_size|
|容器数据卷暂不支持包年包月类型云盘|csi\_not\_portable|sls.app.ack.csi.disk\_not\_portable|
|挂载点正在被进程占用，卸载挂载点失败|csi\_device\_busy|sls.app.ack.csi.deivce\_busy|
|无可用云盘|csi\_no\_ava\_disk|sls.app.ack.csi.no\_ava\_disk|
|云盘IOHang|csi\_disk\_iohang|sls.app.ack.csi.disk\_iohang|
|磁盘绑定的PVC发生slowIO|csi\_latency\_high|sls.app.ack.csi.latency\_too\_high|
|磁盘容量超过水位阈值|disk\_space\_press|sls.app.ack.csi.no\_enough\_disk\_space|

## 如何为专有版集群授予报警功能访问权限

专有版集群在使用报警规则功能之前，需要手动添加权限。

**说明：** 托管版集群已自动添加SLS报警功能资源的访问权限。

为专有版集群SLS报警功能及ARMS-Prometheus报警功能授予资源访问权限。更多信息，请参见[RAM自定义授权场景](/cn.zh-CN/开发指南/访问控制RAM/RAM自定义授权场景.md)及[访问控制概述](/cn.zh-CN/访问控制/访问控制概述.md)。

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，单击**集群**。

3.  在集群列表页面中，单击目标集群名称或者目标集群右侧**操作**列下的**详情**。

4.  在集群信息页面，单击**集群资源**页签**Worker RAM角色**字段右侧的链接，进入RAM访问控制控制台。

    ![worker ram角色](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/5628476161/p255471.png)

5.  在RAM角色管理页面的**权限管理**页签，单击对应**权限策略名称**的链接。

6.  在策略内容页签单击**修改策略内容**，并在右侧的修改策略内容面板将以下内容添加到策略内容中。

    ```
    {
                "Action": [
                    "log:*",
                    "arms:*",
                    "cs:UpdateContactGroup"
                ],
                "Resource": [
                    "*"
                ],
                "Effect": "Allow"
    }
    ```

7.  单击**确定**完成配置。

    **结果验证**

    1.  在[容器服务管理控制台](https://cs.console.aliyun.com)目标集群管理页左侧导航栏，选择**工作负载** \> **无状态**。
    2.  选择**命名空间**kube-system，单击无状态应用列表中alicloud-monitor-controller的**名称**链接。
    3.  单击日志页签，可看到授权成功的Pod日志。

        ![Pod日志](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/0781685161/p249839.png)


