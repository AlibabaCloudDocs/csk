# 事件驱动弹性

ACK支持在控制台上安装ack-keda，提供事件驱动弹性能力。本文介绍事件驱动弹性的概念、原理及如何使用事件驱动弹性。

## 事件驱动弹性概述

Kubernetes中，容器水平伸缩器HPA（Horizontal Pod Autoscaler）是最常用的应用弹性方案。容器水平伸缩的核心是基于资源利用率与预设的阈值水位之间的关系，来确认伸缩的计划。容器水平伸缩的方式具有使用简单、资源指标丰富等特点，但是它对于需要即时弹性的场景，尤其是对基于事件源进行离线作业支撑不足。ACK提供了ack-keda来提供事件驱动弹性能力，事件驱动弹性适用于音视频离线转码、事件驱动作业、流式数据处理等场景。

## 事件驱动弹性的原理

ACK通过增强版本的ack-keda来提供事件驱动弹性能力，下图是ack-keda的基本原理。

![原理](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/1218939061/p208275.png)

ack-keda会从事件源中进行数据的周期性消费。当消息出现堆积，即可秒级触发一个批次的离线任务伸缩。下一个周期到来时，会异步进行下一个批次的作业伸缩。ack-keda具有以下特性：

-   丰富的事件源支持

    ack-keda支持例如Kafka、MySQL、PostgreSQL、Rabbitmq、MongoDB等数据源。更多数据源，请参见[RabbitMQ Queue](https://keda.sh/docs/2.0/scalers/rabbitmq-queue/)。

-   离线任务的并发控制

    对于大规模的离线作业而言，底层管控的稳定性会面临比较大的挑战，需要提供资源、额度、API请求的整体控制。ack-keda提供了单批次、总批次的任务并发控制，保障系统的稳定性。

-   结束任务后自动清理元数据

    大规模离线作业执行完毕后，会留存大量的元数据信息。元数据信息的堆积会造成APIServer的稳定性下降，造成集群的性能下降、稳定性不足，甚至可能影响其他的业务。ack-keda会在任务执行结束后自动清理元数据，降低元数据的量级。


## 步骤一：部署ack-keda

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，选择**市场** \> **应用目录**。

3.  在应用目录页面右上角搜索框中搜索ack-keda，找到然后单击ack-keda。

4.  在应用目录 - ack-keda页面**创建**面板选择目标集群，单击**创建**。

    在控制台左侧导航栏单击**集群**，在集群列表页面中，单击目标集群名称或者目标集群右侧**操作**列下的**详情**。在集群管理页面选择**工作负载** \> **无状态**。在**无状态**页签左上角选择**命名空间**为kube-system，可以看到创建的ack-keda。


## 步骤二：部署事件驱动弹性示例

本示例基于Mongo事件源，通过ack-keda定期查询Mongo数据库中满足`{"region":"eu-1","state":"running","plan":"planA"}`的数据条目。ack-keda扩展ACK中的Job资源，对这些数据分别进行消费处理，同时这些Job将处理完毕的`state`字段标记为done。

1.  部署Mongo DB。

    如果您已有Mongo服务，可跳过此步骤。

    **说明：** 请勿将此数据库用于生产环境。

    1.  创建mongo\_sta\_nodeport.yaml。

        ```
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: mongodb
        spec:
          replicas: 1
          serviceName: mongodb
          selector:
            matchLabels:
              name: mongodb
          template:
            metadata:
              labels:
                name: mongodb
            spec:
              containers:
              - name: mongodb
                image: mongo:4.2.1
                imagePullPolicy: IfNotPresent
                ports:
                - containerPort: 27017
                  name: mongodb
                  protocol: TCP
        ---
        kind: Service
        apiVersion: v1
        metadata:
          name: mongo-test
        spec:
          type: NodePort
          ports:
          - name: mongodb
            port: 27017
            nodePort: 30075
            targetPort: 27017
            protocol: TCP
          selector:
            name: mongodb
        ```

    2.  部署Mongo DB。

        ```
         kubectl apply -f mongo_sta_nodeport.yaml
        ```

2.  登录数据库，注册用户。

    1.  登录数据库。

        ```
        use sample
        ```

    2.  注册用户。

        ```
        db.createUser({ user:"test_user",pwd:"test_password",roles:[{ role:"readWrite", db: "sample"}]})
        ```

    3.  创建Collection。

        ```
        db.createCollection("demo")
        ```

3.  部署ScaledJob和TriggerAuthentication。

    在ack-keda中对于事件源的登录认证需要使用TriggerAuthentication。例如对于Mongo事件源，TriggerAuthentication中的`secretTargetRef`字段会将指定Secret中的连接方式读取到ack-keda中，完成对Mongo的登录认证。

    1.  创建authentication.yaml。

        ```
        apiVersion: keda.sh/v1alpha1
        kind: TriggerAuthentication
        metadata:
          name: mongo-trigger
          namespace: kube-system
        spec:
          secretTargetRef:
            - parameter: connectionString
              name: mongo-secret
              key: connect
        ---
        apiVersion: v1
        kind: Secret
        metadata:
          name: mongo-secret
          namespace: kube-system
        type: Opaque
        data:
          connect: bW9uZ29kYjovL3Rlc3RfdXNlcjp0ZXN0X3Bhc3N3b3JkQDguNDYuMTAuMjE2OjI3MDE3L3NhbXBsZQ==
        ```

    2.  部署TriggerAuthentication和Secret。

        ```
         kubectl apply -f authentication.yaml
        ```

    3.  创建job.yaml。

        ```
        apiVersion: keda.sh/v1alpha1
        kind: ScaledJob
        metadata:
          name: mongo-job
          namespace: kube-system
        spec:
          jobTargetRef:
            template:
              spec:
                containers:
                  - name: mongodb-update
                    image: 1314520999/mongodb-update:latest
                    args:
                    - --connectStr=mongodb://test_user:test_password@8.46.10.216:27017/sample
                    - --dataBase=sample
                    - --collection=demo
                    imagePullPolicy: IfNotPresent
                restartPolicy: Never
            backoffLimit: 1
          pollingInterval: 10
          maxReplicaCount: 30
          successfulJobsHistoryLimit: 0
          failedJobsHistoryLimit: 10
          triggers:
            - type: mongo
              metadata:
                dbName: "sample"
                collection: "demo"
                query: '{"region":"eu-1","state":"running","plan":"planA"}'
                queryValue: "1"
              authenticationRef:
                name: mongo-trigger
        ```

        `query`：配置数据条目。当ack-keda查询到Mongo数据库中有满足该条件的数据条目时，将启动Job资源。

    4.  部署ScaledJob。

        ```
         kubectl apply -f job.yaml
        ```


## 步骤三：验证事件驱动弹性

1.  使用Mongo Shell插入以下一条数据。

    ```
    db.demo.insert({"region":"eu-1","state":"running","plan":"planA","goods":"orange"})
    ```

2.  执行以下命令，查看Job资源。

    根据[步骤二：部署事件驱动弹性示例](#section_14x_42n_nbu)配置的数据条目，ack-keda查询到步骤[1](#step_glc_krj_m6q)插入的数据，启动一个Job进行处理。

    ```
    watch -n 1 kubectl get job -n kube-system
    ```

    ![Job资源](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/0763049061/p208358.png)

    可以看到此时启动一个Job并已执行完毕，实现了在ACK基于Mongo事件源的Pod扩缩容。


