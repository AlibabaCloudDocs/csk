---
keyword: [Spark运行环境, Spark Operator, Alluxio, 提交作业, Spark History Server]
---

# 搭建测试环境

在ACK上运行Spark作业，并用Alluxio进行分布式加速，可以通过ACK Spark Operator来简化提交作业的操作。同时ACK也提供了Spark History Server用来记录作业历史数据，方便排查问题。本文介绍如何在ACK上搭建Spark运行环境。

在ACK上搭建Spark运行的环境包括：

-   [创建ACK集群](#section_g6q_9mp_zts)
-   [创建OSS存储空间](#section_kz3_nkt_pgg)
-   [安装ack-spark-operator](#section_dhf_xau_twq)
-   [安装ack-spark-history-server](#section_4fi_uvq_spe)
-   [安装Alluxio](#section_prv_vcs_oax)

## 创建ACK集群

有关创建ACK集群的具体操作，请参见[创建Kubernetes托管版集群](/cn.zh-CN/Kubernetes集群用户指南/集群/创建集群/创建Kubernetes托管版集群.md)。

**说明：**

配置集群参数时，您需注意以下内容：

-   设置Worker节点的实例规格时，选择**大数据网络增强型**的**ecs.d1ne.6xlarge**规格，并且设置节点数量为20。
-   每个**ecs.d1ne.6xlarge**节点实例自带12块5 TB的HDD数据盘。您需要对这12个数据盘进行分区格式化挂载。有关操作的详情，请参见[分区格式化大于2 TiB数据盘](/cn.zh-CN/块存储/云盘基础操作/分区格式化数据盘/分区格式化大于2 TiB数据盘.md)。
-   格式化并挂载完成后，执行`df -h`可以下图[图 1](#fig_d1e_q7p_wqp)的信息。
-   /mnt目录下的12个文件路径会在Alluxio中用到。当集群节点多时，手工挂载数据盘的操作十分繁琐，ACK简化了操作方式。详情请参见[通过LVM数据卷管理本地存储](/cn.zh-CN/解决方案/大数据解决方案/ACK中运行Spark工作负载/通过LVM数据卷管理本地存储.md)。

![挂载详情](../images/p161287.jpeg "挂载详情")

## 创建OSS存储空间

您需要创建一个OSS存储空间（Bucket）用来存放TPC-DS生成的数据、测试结果和测试过程中的日志等。本文示例中设置Bucket名称为cloudnativeai。有关创建OSS Bucket的具体操作步骤，请参见[创建存储空间](/cn.zh-CN/快速入门/控制台快速入门/创建存储空间.md)。

## 安装ack-spark-operator

通过安装**ack-spark-operator**组件，您可以使用ACK Spark Operator简化提交作业的操作。

1.  登录[容器服务管理控制台](https://cs.console.aliyun.com)。

2.  在控制台左侧导航栏中，选择**市场** \> **应用目录**。

3.  在**应用目录**页面，找到并单击**ack-spark-operator**。

4.  在应用目录 - ack-spark-operator页面右侧，单击**创建**。


## 安装ack-spark-history-server

ACK Spark History Server通过记录Spark执行任务过程中的日志和事件信息，并提供UI界面，帮助排查问题。

在创建**ack-spark-history-server**组件时，您需在**参数**页签配置OSS相关的信息，用于存储Spark历史数据。有关创建**ack-spark-history-server**详细步骤，请参见[安装ack-spark-operator](#section_dhf_xau_twq)。

配置OSS信息如下。

```
oss:
  enableOSS: true
  # Please input your accessKeyId
  alibabaCloudAccessKeyId: ""
  # Please input your accessKeySecret
  alibabaCloudAccessKeySecret: ""
  # oss bucket endpoint such as oss-cn-beijing.aliyuncs.com
  alibabaCloudOSSEndpoint: ""
  # oss file path such as oss://bucket-name/path
  eventsDir: "oss://cloudnativeai/spark/spark-events"
```

安装完成后，执行以下命令查看是否安装成功。

```
kubectl get service ack-spark-history-server -n {YOUR-NAMESPACE}
```

## 安装Alluxio

在ACK中，您需要通过Helm命令安装Alluxio。

1.  首先执行以下命令下载Allxuio。

    ```
    wget http://kubeflow.oss-cn-beijing.aliyuncs.com/alluxio-0.6.8.tgz
    tar -xvf alluxio-0.6.8.tgz
    ```

2.  在Alluxio同级目录下新建并配置config.yaml文件。

    有关完整的配置信息，请参见[config.yaml](https://github.com/AliyunContainerService/benchmark-for-spark/blob/master/kubernetes/alluxio/config.yaml)。

    关键配置如下：

    -   其中以下AccessKey、endpoint、挂载的UFS等信息需要替换成您创建的OSS相关信息。

        ```
        # Site properties for all the components
        properties:
          fs.oss.accessKeyId: YOUR-ACCESS-KEY-ID
          fs.oss.accessKeySecret: YOUR-ACCESS-KEY-SECRET
          fs.oss.endpoint: oss-cn-beijing-internal.aliyuncs.com
          alluxio.master.mount.table.root.ufs: oss://cloudnativeai/
          alluxio.master.persistence.blacklist: .staging,_temporary
          alluxio.security.stale.channel.purge.interval: 365d
          alluxio.user.metrics.collection.enabled: 'true'
          alluxio.user.short.circuit.enabled: 'true'
          alluxio.user.file.write.tier.default: 1
          alluxio.user.block.size.bytes.default: 64MB #default 64MB
          alluxio.user.file.writetype.default: CACHE_THROUGH
          alluxio.user.file.metadata.load.type: ONCE
          alluxio.user.file.readtype.default: CACHE
          #alluxio.worker.allocator.class: alluxio.worker.block.allocator.MaxFreeAllocator
          alluxio.worker.allocator.class: alluxio.worker.block.allocator.RoundRobinAllocator
          alluxio.worker.file.buffer.size: 128MB
          alluxio.worker.evictor.class: alluxio.worker.block.evictor.LRUEvictor
          alluxio.job.master.client.threads: 5000
          alluxio.job.worker.threadpool.size: 300
        ```

    -   tieredstore中的mediumtype、path对应ACK Worker节点中挂载的数据盘。

        ```
        tieredstore:
          levels:
            - level: 0
              alias: HDD
              mediumtype: HDD-0,HDD-1,HDD-2,HDD-3,HDD-4,HDD-5,HDD-6,HDD-7,HDD-8,HDD-9,HDD-10,HDD-11
              path: /mnt/disk1,/mnt/disk2,/mnt/disk3,/mnt/disk4,/mnt/disk5,/mnt/disk6,/mnt/disk7,/mnt/disk8,/mnt/disk9,/mnt/disk10,/mnt/disk11,/mnt/disk12
              type: hostPath
              quota: 1024G,1024G,1024G,1024G,1024G,1024G,1024G,1024G,1024G,1024G,1024G,1024G
              high: 0.95
              low: 0.7
        ```

3.  为ACK集群的Worker节点设置alluxio=true的标签。

    有关添加标签的具体操作步骤，请参见[管理节点标签](/cn.zh-CN/Kubernetes集群用户指南/节点与节点池/节点/管理节点标签.md)。

4.  执行以下Helm命令安装Alluxio。

    ```
    kubectl create namespace alluxio
    helm install -f config.yaml -n alluxio alluxio alluxio
    ```

5.  执行以下命令查看是否成功安装Alluxio。

    ```
    kubectl get pod -n alluxio
    ```

6.  执行以下命令进入alluxio-admin，查看是否成功挂载数据盘。

    ```
    kubectl exec -it alluxio-master-0 -n alluxio -- /bin/bash
    ./bin/alluxio fsadmin report capacity
    ```

    如果能看到每个Worker节点上都有挂载的数据盘，说明Alluxio安装配置成功。

    ![Alluxio](https://static-aliyun-doc.oss-accelerate.aliyuncs.com/assets/img/zh-CN/1804359951/p161392.png)


[开发测试代码](/cn.zh-CN/解决方案/大数据解决方案/ACK中运行Spark工作负载/开发测试代码.md)

